{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2OQHMj4VQjH"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPL8UUahP53E"
      },
      "source": [
        "Worked SO SO GOOD ! ^\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWKkwTUyUI0G"
      },
      "source": [
        "### **Let's try to train** :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aANhYGNCWKAN",
        "outputId": "57357b95-01c8-414a-988e-6cb81cb56abd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss implementation for handling class imbalance\"\"\"\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce_loss(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(focal_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(focal_loss)\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "class DentalDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for dental X-ray images\"\"\"\n",
        "    def __init__(self, annotations, images_dir, transform=None):\n",
        "        self.annotations = annotations\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ann = self.annotations[idx]\n",
        "\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.images_dir, ann['img_file'])\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if image is None:\n",
        "            # Return a dummy image if loading fails\n",
        "            image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Crop with bounding box\n",
        "            x, y, w, h = map(int, ann['bbox'])\n",
        "            cropped = image[y:y+h, x:x+w]\n",
        "\n",
        "            if cropped.size == 0:\n",
        "                image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "            else:\n",
        "                image = cv2.resize(cropped, (224, 224))\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label = ann['label_idx']\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class EfficientNetV2Model(nn.Module):\n",
        "    \"\"\"EfficientNet V2 model for dental classification\"\"\"\n",
        "    def __init__(self, num_classes):\n",
        "        super(EfficientNetV2Model, self).__init__()\n",
        "\n",
        "        # Load pretrained EfficientNet V2 Small\n",
        "        self.efficientnet = models.efficientnet_v2_s(pretrained=True)\n",
        "\n",
        "        # Freeze early layers\n",
        "        for param in list(self.efficientnet.features.parameters())[:30]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Modify classifier\n",
        "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
        "        self.efficientnet.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.efficientnet(x)\n",
        "\n",
        "def load_annotations(annotation_path):\n",
        "    \"\"\"Load annotations from JSON file\"\"\"\n",
        "    with open(annotation_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Create mappings\n",
        "    cat_id_to_name = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    img_id_to_file = {img['id']: img['file_name'] for img in data['images']}\n",
        "\n",
        "    # Process annotations\n",
        "    annotations = []\n",
        "    for ann in data['annotations']:\n",
        "        annotations.append({\n",
        "            'img_file': img_id_to_file[ann['image_id']],\n",
        "            'bbox': ann['bbox'],\n",
        "            'category_id': ann['category_id']\n",
        "        })\n",
        "\n",
        "    return annotations, data['categories'], cat_id_to_name\n",
        "\n",
        "def prepare_datasets(dataset_path, batch_size=16):\n",
        "    \"\"\"Prepare training and validation datasets\"\"\"\n",
        "\n",
        "    # Load annotations\n",
        "    annotation_path = os.path.join(dataset_path, 'train', '_annotations_augmented.json')\n",
        "    images_dir = os.path.join(dataset_path, 'train')\n",
        "\n",
        "    annotations, categories, cat_id_to_name = load_annotations(annotation_path)\n",
        "\n",
        "    # Map category IDs to indices\n",
        "    unique_cat_ids = sorted(set(ann['category_id'] for ann in annotations))\n",
        "    cat_id_to_idx = {cat_id: idx for idx, cat_id in enumerate(unique_cat_ids)}\n",
        "    num_classes = len(unique_cat_ids)\n",
        "\n",
        "    # Count samples per class for class weights\n",
        "    class_counts = defaultdict(int)\n",
        "    for ann in annotations:\n",
        "        cat_id = ann['category_id']\n",
        "        class_counts[cat_id] += 1\n",
        "\n",
        "    # Calculate class weights for balanced training\n",
        "    total_samples = len(annotations)\n",
        "    class_weights = {cat_id: total_samples / (len(class_counts) * count)\n",
        "                    for cat_id, count in class_counts.items()}\n",
        "\n",
        "    # Print class distribution\n",
        "    print(\"Class distribution in dataset:\")\n",
        "    for cat_id, count in class_counts.items():\n",
        "        name = cat_id_to_name.get(cat_id, f\"Unknown ({cat_id})\")\n",
        "        print(f\"  {name}: {count} samples ({count/total_samples*100:.1f}%)\")\n",
        "\n",
        "    # Update annotations with label indices\n",
        "    for ann in annotations:\n",
        "        ann['label_idx'] = cat_id_to_idx[ann['category_id']]\n",
        "\n",
        "    # Split data\n",
        "    train_anns, val_anns = train_test_split(annotations, test_size=0.2, random_state=42,\n",
        "                                           stratify=[ann['category_id'] for ann in annotations])\n",
        "\n",
        "    # Define transforms with data augmentation for training\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = DentalDataset(train_anns, images_dir, transform=train_transform)\n",
        "    val_dataset = DentalDataset(val_anns, images_dir, transform=val_transform)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return train_loader, val_loader, num_classes, cat_id_to_idx, cat_id_to_name, class_weights\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(True):\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        total_samples += inputs.size(0)\n",
        "\n",
        "        # Store predictions and labels for confusion matrix\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = running_corrects.double() / total_samples\n",
        "\n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    \"\"\"Validate for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Validating\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            # Store predictions and labels for confusion matrix\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = running_corrects.double() / total_samples\n",
        "\n",
        "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, cat_id_to_name, cat_id_to_idx, idx_to_cat_id, phase=\"validation\"):\n",
        "    \"\"\"Plot confusion matrix for each class\"\"\"\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Get class names\n",
        "    class_names = [cat_id_to_name[idx_to_cat_id[i]] for i in range(len(cat_id_to_idx))]\n",
        "\n",
        "    # Plot overall confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'Confusion Matrix - {phase.capitalize()}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{phase}_confusion_matrix.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Calculate and plot per-class metrics\n",
        "    classification_rep = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "\n",
        "    # Plot individual class performance\n",
        "    metrics = ['precision', 'recall', 'f1-score']\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Create a bar chart for each metric\n",
        "    for i, metric in enumerate(metrics):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        values = [classification_rep[class_name][metric] for class_name in class_names]\n",
        "        sns.barplot(x=class_names, y=values)\n",
        "        plt.title(f'{metric.capitalize()} by Class - {phase.capitalize()}')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{phase}_class_metrics.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Calculate per-class error rate\n",
        "    error_rates = {}\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        # Get indices of this class\n",
        "        class_indices = [j for j, l in enumerate(y_true) if l == i]\n",
        "        if class_indices:\n",
        "            # Calculate error rate for this class\n",
        "            class_errors = sum(1 for j in class_indices if y_pred[j] != y_true[j])\n",
        "            error_rate = class_errors / len(class_indices)\n",
        "            error_rates[class_name] = error_rate\n",
        "\n",
        "    # Plot error rates\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    names = list(error_rates.keys())\n",
        "    values = list(error_rates.values())\n",
        "\n",
        "    sns.barplot(x=names, y=values)\n",
        "    plt.title(f'Classification Error Rate by Class - {phase.capitalize()}')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.ylabel('Error Rate')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{phase}_error_rates.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"\\n{phase.capitalize()} Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "    return classification_rep\n",
        "\n",
        "def train_model(dataset_path='/content/vzrad2-4', epochs=15, batch_size=16, learning_rate=0.0001,\n",
        "               focal_loss_gamma=2.0):\n",
        "    \"\"\"Main training function with Focal Loss\"\"\"\n",
        "\n",
        "    # Prepare datasets\n",
        "    print(\"ðŸ”„ Preparing datasets...\")\n",
        "    train_loader, val_loader, num_classes, cat_id_to_idx, cat_id_to_name, class_weights = prepare_datasets(dataset_path, batch_size)\n",
        "    idx_to_cat_id = {v: k for k, v in cat_id_to_idx.items()}\n",
        "\n",
        "    # Create model\n",
        "    print(f\"ðŸ”„ Creating EfficientNet V2 model with {num_classes} classes...\")\n",
        "    model = EfficientNetV2Model(num_classes).to(device)\n",
        "\n",
        "    # Define loss function - Focal Loss\n",
        "    print(f\"ðŸ”„ Using Focal Loss with gamma={focal_loss_gamma}\")\n",
        "    criterion = FocalLoss(gamma=focal_loss_gamma)\n",
        "\n",
        "    # Define optimizer with weight decay to prevent overfitting\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "    # Learning rate scheduler - reduce on plateau\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': [],\n",
        "        'learning_rate': []\n",
        "    }\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_model_state = None\n",
        "    best_epoch = 0\n",
        "\n",
        "    # Training loop\n",
        "    print(\"ðŸ”„ Starting training...\")\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc, train_preds, train_labels = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc, val_preds, val_labels = validate_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        # Get current learning rate\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        # Save history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc.item())\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc.item())\n",
        "        history['learning_rate'].append(current_lr)\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict()\n",
        "            best_epoch = epoch\n",
        "            torch.save(best_model_state, 'best_model.pth')\n",
        "            print(f\"âœ… New best model saved! (Epoch {epoch+1})\")\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} - Val Acc: {val_acc:.4f}\")\n",
        "        print(f\"Learning Rate: {current_lr:.8f}\")\n",
        "\n",
        "        # Plot confusion matrix every 5 epochs and on last epoch\n",
        "        if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
        "            print(\"\\nðŸ”„ Generating confusion matrices...\")\n",
        "            train_metrics = plot_confusion_matrix(train_labels, train_preds, cat_id_to_name, cat_id_to_idx, idx_to_cat_id, \"train\")\n",
        "            val_metrics = plot_confusion_matrix(val_labels, val_preds, cat_id_to_name, cat_id_to_idx, idx_to_cat_id, \"validation\")\n",
        "\n",
        "    # Plot training metrics over time\n",
        "    plt.figure(figsize=(15, 12))\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
        "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
        "    plt.axvline(x=best_epoch, color='r', linestyle='--', label=f'Best Model (Epoch {best_epoch+1})')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.axvline(x=best_epoch, color='r', linestyle='--', label=f'Best Model (Epoch {best_epoch+1})')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Learning rate plot\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.plot(history['learning_rate'], label='Learning Rate', color='g')\n",
        "    plt.axvline(x=best_epoch, color='r', linestyle='--', label=f'Best Model (Epoch {best_epoch+1})')\n",
        "    plt.title('Learning Rate')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_metrics.png')\n",
        "    plt.show()\n",
        "\n",
        "    # Print training history\n",
        "    print(\"\\nðŸ“Š Training History:\")\n",
        "    print(f\"{'Epoch':>5} | {'Train Loss':>10} | {'Train Acc':>10} | {'Val Loss':>10} | {'Val Acc':>10} | {'LR':>10}\")\n",
        "    print(\"-\" * 65)\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"{epoch+1:5d} | {history['train_loss'][epoch]:10.4f} | {history['train_acc'][epoch]:10.4f} | \"\n",
        "              f\"{history['val_loss'][epoch]:10.4f} | {history['val_acc'][epoch]:10.4f} | {history['learning_rate'][epoch]:10.8f}\")\n",
        "\n",
        "    # Save final model\n",
        "    torch.save(model.state_dict(), 'final_model.pth')\n",
        "\n",
        "    # Save history\n",
        "    with open('training_history.pkl', 'wb') as f:\n",
        "        pickle.dump(history, f)\n",
        "\n",
        "    # Save category mapping\n",
        "    mapping_data = {\n",
        "        'cat_id_to_idx': cat_id_to_idx,\n",
        "        'cat_id_to_name': cat_id_to_name\n",
        "    }\n",
        "    with open('category_mapping.pkl', 'wb') as f:\n",
        "        pickle.dump(mapping_data, f)\n",
        "\n",
        "    # Print final metrics\n",
        "    print(\"\\nâœ… Training completed!\")\n",
        "    print(f\"Best validation accuracy: {best_val_acc:.4f} (Epoch {best_epoch+1})\")\n",
        "    print(f\"Final train accuracy: {history['train_acc'][-1]:.4f}\")\n",
        "    print(f\"Final validation accuracy: {history['val_acc'][-1]:.4f}\")\n",
        "\n",
        "    # Load the best model for final evaluation\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    print(f\"\\nLoaded best model from epoch {best_epoch+1} for final evaluation\")\n",
        "\n",
        "    # Final evaluation on validation set\n",
        "    final_val_loss, final_val_acc, final_val_preds, final_val_labels = validate_epoch(model, val_loader, criterion, device)\n",
        "    print(f\"Best model validation accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "    # Generate final confusion matrix\n",
        "    final_metrics = plot_confusion_matrix(final_val_labels, final_val_preds, cat_id_to_name, cat_id_to_idx, idx_to_cat_id, \"best_model\")\n",
        "\n",
        "    return model, history, mapping_data\n",
        "\n",
        "# Run the training\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        model, history, mapping = train_model(\n",
        "            batch_size=16,\n",
        "            epochs=15,\n",
        "            learning_rate=0.0001,\n",
        "            focal_loss_gamma=2.0  # Adjust gamma parameter for focal loss\n",
        "        )\n",
        "        print(\"âœ… Training pipeline completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Training pipeline failed: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pf9y0qWa2Yu_",
        "outputId": "a2b20b03-56d9-4ad6-eeb6-4543133013f6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss implementation for handling class imbalance\"\"\"\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce_loss(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(focal_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(focal_loss)\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "class DentalDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for dental X-ray images\"\"\"\n",
        "    def __init__(self, annotations, images_dir, transform=None, return_info=False):\n",
        "        self.annotations = annotations\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "        self.return_info = return_info\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ann = self.annotations[idx]\n",
        "\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.images_dir, ann['img_file'])\n",
        "        image = cv2.imread(img_path)\n",
        "        original_image = image.copy() if image is not None else None\n",
        "\n",
        "        if image is None:\n",
        "            # Return a dummy image if loading fails\n",
        "            image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Crop with bounding box\n",
        "            x, y, w, h = map(int, ann['bbox'])\n",
        "            cropped = image[y:y+h, x:x+w]\n",
        "\n",
        "            if cropped.size == 0:\n",
        "                image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "            else:\n",
        "                image = cv2.resize(cropped, (224, 224))\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label = ann['label_idx']\n",
        "\n",
        "        if self.return_info:\n",
        "            return image, label, img_path, ann['bbox'], original_image\n",
        "        else:\n",
        "            return image, label\n",
        "\n",
        "class EfficientNetV2Model(nn.Module):\n",
        "    \"\"\"EfficientNet V2 model for dental classification\"\"\"\n",
        "    def __init__(self, num_classes):\n",
        "        super(EfficientNetV2Model, self).__init__()\n",
        "\n",
        "        # Load pretrained EfficientNet V2 Small\n",
        "        self.efficientnet = models.efficientnet_v2_s(pretrained=True)\n",
        "\n",
        "        # Freeze early layers\n",
        "        for param in list(self.efficientnet.features.parameters())[:30]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Modify classifier\n",
        "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
        "        self.efficientnet.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.efficientnet(x)\n",
        "\n",
        "def load_annotations(annotation_path):\n",
        "    \"\"\"Load annotations from JSON file\"\"\"\n",
        "    with open(annotation_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Create mappings\n",
        "    cat_id_to_name = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    img_id_to_file = {img['id']: img['file_name'] for img in data['images']}\n",
        "\n",
        "    # Process annotations\n",
        "    annotations = []\n",
        "    for ann in data['annotations']:\n",
        "        annotations.append({\n",
        "            'img_file': img_id_to_file[ann['image_id']],\n",
        "            'bbox': ann['bbox'],\n",
        "            'category_id': ann['category_id']\n",
        "        })\n",
        "\n",
        "    return annotations, data['categories'], cat_id_to_name\n",
        "\n",
        "def prepare_test_dataset(dataset_path, batch_size=16):\n",
        "    \"\"\"Prepare test dataset\"\"\"\n",
        "\n",
        "    # Load annotations\n",
        "    annotation_path = os.path.join(dataset_path, 'test', '_annotations.json')\n",
        "    images_dir = os.path.join(dataset_path, 'test')\n",
        "\n",
        "    # Check if test set exists, otherwise use validation from training data\n",
        "    if not os.path.exists(annotation_path):\n",
        "        annotation_path = os.path.join(dataset_path, 'train', '_annotations_augmented.json')\n",
        "        images_dir = os.path.join(dataset_path, 'train')\n",
        "        print(\"Test set not found, using validation split from training data\")\n",
        "\n",
        "    annotations, categories, cat_id_to_name = load_annotations(annotation_path)\n",
        "\n",
        "    # Map category IDs to indices\n",
        "    unique_cat_ids = sorted(set(ann['category_id'] for ann in annotations))\n",
        "    cat_id_to_idx = {cat_id: idx for idx, cat_id in enumerate(unique_cat_ids)}\n",
        "    num_classes = len(unique_cat_ids)\n",
        "\n",
        "    # Update annotations with label indices\n",
        "    for ann in annotations:\n",
        "        ann['label_idx'] = cat_id_to_idx[ann['category_id']]\n",
        "\n",
        "    # If using training data, split into test\n",
        "    if 'test' not in annotation_path:\n",
        "        _, test_anns = train_test_split(annotations, test_size=0.2, random_state=42,\n",
        "                                       stratify=[ann['category_id'] for ann in annotations])\n",
        "    else:\n",
        "        test_anns = annotations\n",
        "\n",
        "    # Define transforms\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    test_dataset = DentalDataset(test_anns, images_dir, transform=test_transform, return_info=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return test_loader, num_classes, cat_id_to_idx, cat_id_to_name\n",
        "\n",
        "def plot_per_class_confusion_matrix(y_true, y_pred, cat_id_to_name, idx_to_cat_id):\n",
        "    \"\"\"Plot confusion matrix for each class individually, 5 per figure\"\"\"\n",
        "\n",
        "    # Get unique labels from both y_true and y_pred\n",
        "    unique_labels = sorted(set(y_true) | set(y_pred))\n",
        "\n",
        "    # Calculate overall confusion matrix with all possible labels\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=unique_labels)\n",
        "\n",
        "    # Split into multiple figures, 5 classes per figure\n",
        "    classes_per_fig = 5\n",
        "    n_figures = (len(unique_labels) + classes_per_fig - 1) // classes_per_fig\n",
        "\n",
        "    for fig_idx in range(n_figures):\n",
        "        plt.figure(figsize=(20, 4))\n",
        "        start_idx = fig_idx * classes_per_fig\n",
        "        end_idx = min(start_idx + classes_per_fig, len(unique_labels))\n",
        "\n",
        "        for i, label_idx in enumerate(unique_labels[start_idx:end_idx]):\n",
        "            plt.subplot(1, classes_per_fig, i + 1)\n",
        "\n",
        "            # Find position of this label in the confusion matrix\n",
        "            label_pos = unique_labels.index(label_idx)\n",
        "\n",
        "            # Extract 2x2 matrix for this class (binary classification: this class vs all others)\n",
        "            true_positives = cm[label_pos, label_pos]\n",
        "            false_positives = sum(cm[:, label_pos]) - true_positives\n",
        "            false_negatives = sum(cm[label_pos, :]) - true_positives\n",
        "            true_negatives = sum(sum(cm)) - true_positives - false_positives - false_negatives\n",
        "\n",
        "            binary_cm = np.array([[true_negatives, false_positives],\n",
        "                                  [false_negatives, true_positives]])\n",
        "\n",
        "            # Calculate metrics\n",
        "            precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "            recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            # Get class name\n",
        "            class_name = cat_id_to_name[idx_to_cat_id[label_idx]] if label_idx in idx_to_cat_id else f\"Class {label_idx}\"\n",
        "\n",
        "            # Plot\n",
        "            sns.heatmap(binary_cm, annot=True, fmt='d', cmap='Blues',\n",
        "                        xticklabels=['Other', 'Class'],\n",
        "                        yticklabels=['Other', 'Class'],\n",
        "                        cbar=False)\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('True')\n",
        "            plt.title(f'{class_name}\\n'\n",
        "                     f'Prec: {precision:.2f}, Rec: {recall:.2f}, F1: {f1:.2f}', fontsize=12)\n",
        "\n",
        "            # Add percentages as annotation\n",
        "            total = sum(sum(binary_cm))\n",
        "            for y in range(2):\n",
        "                for x in range(2):\n",
        "                    plt.text(x + 0.5, y + 0.7, f'{100 * binary_cm[y, x] / total:.1f}%',\n",
        "                            horizontalalignment='center',\n",
        "                            color='red' if binary_cm[y, x] < 100 else 'black',\n",
        "                            fontsize=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'individual_class_confusion_matrices_{fig_idx+1}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()  # Display the figure\n",
        "        plt.close()\n",
        "\n",
        "def plot_example_classes(y_true, y_pred, cat_id_to_name, idx_to_cat_id, n_classes=5):\n",
        "    \"\"\"Plot confusion matrices for n example classes in a single figure\"\"\"\n",
        "\n",
        "    # Get unique labels from both y_true and y_pred\n",
        "    unique_labels = sorted(set(y_true) | set(y_pred))[:n_classes]\n",
        "\n",
        "    # Calculate overall confusion matrix with all possible labels\n",
        "    all_labels = sorted(set(y_true) | set(y_pred))\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=all_labels)\n",
        "\n",
        "    plt.figure(figsize=(20, 4))\n",
        "\n",
        "    for i, label_idx in enumerate(unique_labels):\n",
        "        plt.subplot(1, n_classes, i + 1)\n",
        "\n",
        "        # Find position of this label in the confusion matrix\n",
        "        label_pos = all_labels.index(label_idx)\n",
        "\n",
        "        # Extract 2x2 matrix for this class (binary classification: this class vs all others)\n",
        "        true_positives = cm[label_pos, label_pos]\n",
        "        false_positives = sum(cm[:, label_pos]) - true_positives\n",
        "        false_negatives = sum(cm[label_pos, :]) - true_positives\n",
        "        true_negatives = sum(sum(cm)) - true_positives - false_positives - false_negatives\n",
        "\n",
        "        binary_cm = np.array([[true_negatives, false_positives],\n",
        "                              [false_negatives, true_positives]])\n",
        "\n",
        "        # Calculate metrics\n",
        "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        # Get class name\n",
        "        class_name = cat_id_to_name[idx_to_cat_id[label_idx]] if label_idx in idx_to_cat_id else f\"Class {label_idx}\"\n",
        "\n",
        "        # Plot\n",
        "        sns.heatmap(binary_cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=['Not ' + class_name, class_name],\n",
        "                    yticklabels=['Not ' + class_name, class_name],\n",
        "                    cbar=False)\n",
        "        plt.xlabel('Predicted', fontsize=12)\n",
        "        plt.ylabel('True', fontsize=12)\n",
        "        plt.title(f'{class_name}\\n'\n",
        "                 f'Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}', fontsize=12)\n",
        "\n",
        "        # Add percentages as annotation\n",
        "        total = sum(sum(binary_cm))\n",
        "        for y in range(2):\n",
        "            for x in range(2):\n",
        "                plt.text(x + 0.5, y + 0.7, f'{100 * binary_cm[y, x] / total:.1f}%',\n",
        "                        horizontalalignment='center',\n",
        "                        color='red' if binary_cm[y, x] < 100 else 'black',\n",
        "                        fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('example_individual_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()  # Display the figure\n",
        "    plt.close()\n",
        "\n",
        "def visualize_predictions(model, test_loader, cat_id_to_name, idx_to_cat_id, device, num_samples=5):\n",
        "    \"\"\"Visualize sample predictions with bounding boxes for ground truth and predictions\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Get random samples\n",
        "    sample_indices = random.sample(range(len(test_loader.dataset)), num_samples)\n",
        "\n",
        "    plt.figure(figsize=(15, 5*num_samples))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, sample_idx in enumerate(sample_indices):\n",
        "            image, label, img_path, bbox, original_image = test_loader.dataset[sample_idx]\n",
        "\n",
        "            # Skip if original image is None\n",
        "            if original_image is None:\n",
        "                continue\n",
        "\n",
        "            # Get prediction\n",
        "            input_tensor = image.unsqueeze(0).to(device)\n",
        "            outputs = model(input_tensor)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            pred_idx = pred.item()\n",
        "\n",
        "            # Get class names\n",
        "            true_class = cat_id_to_name[idx_to_cat_id[label]] if label in idx_to_cat_id else f\"Class {label}\"\n",
        "            pred_class = cat_id_to_name[idx_to_cat_id[pred_idx]] if pred_idx in idx_to_cat_id else f\"Class {pred_idx}\"\n",
        "\n",
        "            # Create visualization with ground truth\n",
        "            plt.subplot(num_samples, 2, idx*2 + 1)\n",
        "            img_with_gt = original_image.copy()\n",
        "            x, y, w, h = map(int, bbox)\n",
        "            cv2.rectangle(img_with_gt, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
        "            cv2.putText(img_with_gt, f\"GT: {true_class}\", (x, y-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "            plt.imshow(cv2.cvtColor(img_with_gt, cv2.COLOR_BGR2RGB))\n",
        "            plt.title('Ground Truth')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Create visualization with prediction\n",
        "            plt.subplot(num_samples, 2, idx*2 + 2)\n",
        "            img_with_pred = original_image.copy()\n",
        "            color = (0, 255, 0) if pred_idx == label else (0, 0, 255)\n",
        "            cv2.rectangle(img_with_pred, (x, y), (x+w, y+h), color, 3)\n",
        "            cv2.putText(img_with_pred, f\"Pred: {pred_class}\", (x, y-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "            plt.imshow(cv2.cvtColor(img_with_pred, cv2.COLOR_BGR2RGB))\n",
        "            plt.title('Prediction')\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('prediction_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def test_model(dataset_path, model_path, mapping_path, batch_size=16):\n",
        "    \"\"\"Comprehensive test function with all requested features\"\"\"\n",
        "\n",
        "    print(\"ðŸ”„ Preparing test dataset...\")\n",
        "    test_loader, num_classes, cat_id_to_idx, cat_id_to_name = prepare_test_dataset(dataset_path, batch_size)\n",
        "    idx_to_cat_id = {v: k for k, v in cat_id_to_idx.items()}\n",
        "\n",
        "    # Load model\n",
        "    print(\"ðŸ”„ Loading model...\")\n",
        "    model = EfficientNetV2Model(num_classes).to(device)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    # Define criterion\n",
        "    criterion = FocalLoss(gamma=2.0)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"ðŸ”„ Evaluating on test set...\")\n",
        "    test_loss = 0.0\n",
        "    test_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, *_ in tqdm(test_loader, desc=\"Testing\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            test_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_loss = test_loss / total_samples\n",
        "    test_acc = test_corrects.double() / total_samples\n",
        "\n",
        "    print(f\"\\nðŸ“Š Test Results:\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Generate overall confusion matrix\n",
        "    print(\"\\nðŸ”„ Generating overall confusion matrix...\")\n",
        "    unique_labels = sorted(set(all_labels) | set(all_preds))\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=unique_labels)\n",
        "    class_names = []\n",
        "    for label in unique_labels:\n",
        "        if label in idx_to_cat_id:\n",
        "            class_names.append(cat_id_to_name[idx_to_cat_id[label]])\n",
        "        else:\n",
        "            class_names.append(f\"Class {label}\")\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Overall Confusion Matrix - Test Set')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('test_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Generate classification report\n",
        "    print(\"\\nðŸ“Š Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names, labels=unique_labels))\n",
        "\n",
        "    # Generate individual class confusion matrices\n",
        "    print(\"\\nðŸ”„ Generating individual class confusion matrices...\")\n",
        "    plot_per_class_confusion_matrix(all_labels, all_preds, cat_id_to_name, idx_to_cat_id)\n",
        "\n",
        "    # Analyze classification errors\n",
        "    print(\"\\nðŸ”„ Analyzing classification errors...\")\n",
        "    plot_error_analysis(all_labels, all_preds, cat_id_to_name, idx_to_cat_id)\n",
        "\n",
        "    # Visualize sample predictions\n",
        "    print(\"\\nðŸ”„ Visualizing sample predictions...\")\n",
        "    visualize_predictions(model, test_loader, cat_id_to_name, idx_to_cat_id, device)\n",
        "\n",
        "    # Save test results\n",
        "    test_results = {\n",
        "        'test_loss': test_loss,\n",
        "        'test_accuracy': test_acc,\n",
        "        'predictions': all_preds,\n",
        "        'labels': all_labels,\n",
        "        'classification_report': classification_report(all_labels, all_preds, target_names=class_names, labels=unique_labels, output_dict=True)\n",
        "    }\n",
        "\n",
        "    with open('test_results.pkl', 'wb') as f:\n",
        "        pickle.dump(test_results, f)\n",
        "\n",
        "    print(\"\\nâœ… Testing completed successfully!\")\n",
        "    print(f\"Final test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Run testing\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        test_model(\n",
        "            dataset_path='/content/vzrad2-4',\n",
        "            model_path='best_model.pth',\n",
        "            mapping_path='category_mapping.pkl',\n",
        "            batch_size=16\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Testing failed: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcdGNk1Byn3I"
      },
      "source": [
        "**With mAP** :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_h_mnsVzQdU",
        "outputId": "64777e57-0e6c-4eda-ca01-1a72ff99892f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, classification_report, average_precision_score\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss implementation for handling class imbalance\"\"\"\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.ce_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = self.ce_loss(inputs, targets)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(focal_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(focal_loss)\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "class DentalDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for dental X-ray images\"\"\"\n",
        "    def __init__(self, annotations, images_dir, transform=None, return_info=False):\n",
        "        self.annotations = annotations\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "        self.return_info = return_info\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ann = self.annotations[idx]\n",
        "\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.images_dir, ann['img_file'])\n",
        "        image = cv2.imread(img_path)\n",
        "        original_image = image.copy() if image is not None else None\n",
        "\n",
        "        if image is None:\n",
        "            # Return a dummy image if loading fails\n",
        "            image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Crop with bounding box\n",
        "            x, y, w, h = map(int, ann['bbox'])\n",
        "            cropped = image[y:y+h, x:x+w]\n",
        "\n",
        "            if cropped.size == 0:\n",
        "                image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "            else:\n",
        "                image = cv2.resize(cropped, (224, 224))\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert label to tensor\n",
        "        label = ann['label_idx']\n",
        "\n",
        "        if self.return_info:\n",
        "            return image, label, img_path, ann['bbox'], original_image\n",
        "        else:\n",
        "            return image, label\n",
        "\n",
        "class EfficientNetV2Model(nn.Module):\n",
        "    \"\"\"EfficientNet V2 model for dental classification\"\"\"\n",
        "    def __init__(self, num_classes):\n",
        "        super(EfficientNetV2Model, self).__init__()\n",
        "\n",
        "        # Load pretrained EfficientNet V2 Small\n",
        "        self.efficientnet = models.efficientnet_v2_s(pretrained=True)\n",
        "\n",
        "        # Freeze early layers\n",
        "        for param in list(self.efficientnet.features.parameters())[:30]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Modify classifier\n",
        "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
        "        self.efficientnet.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.efficientnet(x)\n",
        "\n",
        "def load_annotations(annotation_path):\n",
        "    \"\"\"Load annotations from JSON file\"\"\"\n",
        "    with open(annotation_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Create mappings\n",
        "    cat_id_to_name = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    img_id_to_file = {img['id']: img['file_name'] for img in data['images']}\n",
        "\n",
        "    # Process annotations\n",
        "    annotations = []\n",
        "    for ann in data['annotations']:\n",
        "        annotations.append({\n",
        "            'img_file': img_id_to_file[ann['image_id']],\n",
        "            'bbox': ann['bbox'],\n",
        "            'category_id': ann['category_id']\n",
        "        })\n",
        "\n",
        "    return annotations, data['categories'], cat_id_to_name\n",
        "\n",
        "def prepare_test_dataset(dataset_path, batch_size=16):\n",
        "    \"\"\"Prepare test dataset\"\"\"\n",
        "\n",
        "    # Load annotations\n",
        "    annotation_path = os.path.join(dataset_path, 'test', '_annotations.json')\n",
        "    images_dir = os.path.join(dataset_path, 'test')\n",
        "\n",
        "    # Check if test set exists, otherwise use validation from training data\n",
        "    if not os.path.exists(annotation_path):\n",
        "        annotation_path = os.path.join(dataset_path, 'train', '_annotations_augmented.json')\n",
        "        images_dir = os.path.join(dataset_path, 'train')\n",
        "        print(\"Test set not found, using validation split from training data\")\n",
        "\n",
        "    annotations, categories, cat_id_to_name = load_annotations(annotation_path)\n",
        "\n",
        "    # Map category IDs to indices\n",
        "    unique_cat_ids = sorted(set(ann['category_id'] for ann in annotations))\n",
        "    cat_id_to_idx = {cat_id: idx for idx, cat_id in enumerate(unique_cat_ids)}\n",
        "    num_classes = len(unique_cat_ids)\n",
        "\n",
        "    # Count samples per class\n",
        "    class_counts = defaultdict(int)\n",
        "    for ann in annotations:\n",
        "        cat_id = ann['category_id']\n",
        "        class_counts[cat_id] += 1\n",
        "\n",
        "    # Print class distribution\n",
        "    total_samples = len(annotations)\n",
        "    print(\"Class distribution in test dataset:\")\n",
        "    for cat_id, count in class_counts.items():\n",
        "        name = cat_id_to_name.get(cat_id, f\"Unknown ({cat_id})\")\n",
        "        print(f\"  {name}: {count} samples ({count/total_samples*100:.1f}%)\")\n",
        "\n",
        "    # Update annotations with label indices\n",
        "    for ann in annotations:\n",
        "        ann['label_idx'] = cat_id_to_idx[ann['category_id']]\n",
        "\n",
        "    # If using training data, split into test\n",
        "    if 'test' not in annotation_path:\n",
        "        _, test_anns = train_test_split(annotations, test_size=0.2, random_state=42,\n",
        "                                       stratify=[ann['category_id'] for ann in annotations])\n",
        "    else:\n",
        "        test_anns = annotations\n",
        "\n",
        "    # Define transforms\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    test_dataset = DentalDataset(test_anns, images_dir, transform=test_transform, return_info=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    return test_loader, num_classes, cat_id_to_idx, cat_id_to_name\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, cat_id_to_name, cat_id_to_idx, idx_to_cat_id, phase=\"test\"):\n",
        "    \"\"\"Plot confusion matrix for test data\"\"\"\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    unique_labels = sorted(set(y_true) | set(y_pred))\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=unique_labels)\n",
        "\n",
        "    # Get class names\n",
        "    class_names = []\n",
        "    for label in unique_labels:\n",
        "        if label in idx_to_cat_id:\n",
        "            class_names.append(cat_id_to_name[idx_to_cat_id[label]])\n",
        "        else:\n",
        "            class_names.append(f\"Class {label}\")\n",
        "\n",
        "    # Plot overall confusion matrix\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'Confusion Matrix - {phase.capitalize()}')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{phase}_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Calculate and plot per-class metrics\n",
        "    classification_rep = classification_report(y_true, y_pred, target_names=class_names,\n",
        "                                              labels=unique_labels, output_dict=True)\n",
        "\n",
        "    # Plot individual class performance\n",
        "    metrics = ['precision', 'recall', 'f1-score']\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Create a bar chart for each metric\n",
        "    for i, metric in enumerate(metrics):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        values = [classification_rep[class_name][metric] for class_name in class_names]\n",
        "        sns.barplot(x=class_names, y=values)\n",
        "        plt.title(f'{metric.capitalize()} by Class - {phase.capitalize()}')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{phase}_class_metrics.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"\\nðŸ“Š {phase.capitalize()} Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names, labels=unique_labels))\n",
        "\n",
        "    return classification_rep\n",
        "\n",
        "def plot_per_class_confusion_matrix(y_true, y_pred, cat_id_to_name, idx_to_cat_id):\n",
        "    \"\"\"Plot confusion matrix for each class individually, 5 per figure\"\"\"\n",
        "\n",
        "    # Get unique labels from both y_true and y_pred\n",
        "    unique_labels = sorted(set(y_true) | set(y_pred))\n",
        "\n",
        "    # Calculate overall confusion matrix with all possible labels\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=unique_labels)\n",
        "\n",
        "    # Split into multiple figures, 5 classes per figure\n",
        "    classes_per_fig = 5\n",
        "    n_figures = (len(unique_labels) + classes_per_fig - 1) // classes_per_fig\n",
        "\n",
        "    for fig_idx in range(n_figures):\n",
        "        plt.figure(figsize=(20, 4))\n",
        "        start_idx = fig_idx * classes_per_fig\n",
        "        end_idx = min(start_idx + classes_per_fig, len(unique_labels))\n",
        "\n",
        "        for i, label_idx in enumerate(unique_labels[start_idx:end_idx]):\n",
        "            plt.subplot(1, classes_per_fig, i + 1)\n",
        "\n",
        "            # Find position of this label in the confusion matrix\n",
        "            label_pos = unique_labels.index(label_idx)\n",
        "\n",
        "            # Extract 2x2 matrix for this class (binary classification: this class vs all others)\n",
        "            true_positives = cm[label_pos, label_pos]\n",
        "            false_positives = sum(cm[:, label_pos]) - true_positives\n",
        "            false_negatives = sum(cm[label_pos, :]) - true_positives\n",
        "            true_negatives = sum(sum(cm)) - true_positives - false_positives - false_negatives\n",
        "\n",
        "            binary_cm = np.array([[true_negatives, false_positives],\n",
        "                                  [false_negatives, true_positives]])\n",
        "\n",
        "            # Calculate metrics\n",
        "            precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "            recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            # Get class name\n",
        "            class_name = cat_id_to_name[idx_to_cat_id[label_idx]] if label_idx in idx_to_cat_id else f\"Class {label_idx}\"\n",
        "\n",
        "            # Plot\n",
        "            sns.heatmap(binary_cm, annot=True, fmt='d', cmap='Blues',\n",
        "                        xticklabels=['Other', 'Class'],\n",
        "                        yticklabels=['Other', 'Class'],\n",
        "                        cbar=False)\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('True')\n",
        "            plt.title(f'{class_name}\\n'\n",
        "                     f'Prec: {precision:.2f}, Rec: {recall:.2f}, F1: {f1:.2f}', fontsize=12)\n",
        "\n",
        "            # Add percentages as annotation\n",
        "            total = sum(sum(binary_cm))\n",
        "            for y in range(2):\n",
        "                for x in range(2):\n",
        "                    plt.text(x + 0.5, y + 0.7, f'{100 * binary_cm[y, x] / total:.1f}%',\n",
        "                            horizontalalignment='center',\n",
        "                            color='red' if binary_cm[y, x] < 100 else 'black',\n",
        "                            fontsize=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'individual_class_confusion_matrices_{fig_idx+1}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "def plot_error_analysis(y_true, y_pred, cat_id_to_name, idx_to_cat_id):\n",
        "    \"\"\"Analyze and visualize classification errors\"\"\"\n",
        "    from collections import Counter, defaultdict\n",
        "\n",
        "    # Create a dictionary to store misclassifications\n",
        "    error_dict = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Count misclassifications\n",
        "    for true_label, pred_label in zip(y_true, y_pred):\n",
        "        if true_label != pred_label:\n",
        "            true_class = cat_id_to_name[idx_to_cat_id[true_label]] if true_label in idx_to_cat_id else f\"Class {true_label}\"\n",
        "            pred_class = cat_id_to_name[idx_to_cat_id[pred_label]] if pred_label in idx_to_cat_id else f\"Class {pred_label}\"\n",
        "            error_dict[true_class][pred_class] += 1\n",
        "\n",
        "    # Find top 10 most frequent misclassifications\n",
        "    error_counts = []\n",
        "    for true_class, pred_dict in error_dict.items():\n",
        "        for pred_class, count in pred_dict.items():\n",
        "            error_counts.append((true_class, pred_class, count))\n",
        "\n",
        "    # Sort errors by count in descending order\n",
        "    top_errors = sorted(error_counts, key=lambda x: x[2], reverse=True)[:10]\n",
        "\n",
        "    # Visualize top 10 misclassifications\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    true_classes = [err[0] for err in top_errors]\n",
        "    pred_classes = [err[1] for err in top_errors]\n",
        "    counts = [err[2] for err in top_errors]\n",
        "\n",
        "    # Create x positions\n",
        "    x_pos = np.arange(len(top_errors))\n",
        "\n",
        "    # Create bar chart\n",
        "    bars = plt.barh(x_pos, counts, align='center', alpha=0.7)\n",
        "\n",
        "    # Add count labels to the bars\n",
        "    for i, bar in enumerate(bars):\n",
        "        plt.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,\n",
        "                str(counts[i]), ha='left', va='center')\n",
        "\n",
        "    # Add labels\n",
        "    plt.yticks(x_pos, [f\"{true} â†’ {pred}\" for true, pred in zip(true_classes, pred_classes)])\n",
        "    plt.xlabel('Number of misclassifications')\n",
        "    plt.title('Top 10 Most Frequent Misclassifications')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('top_misclassifications.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    # Analyze most confused classes\n",
        "    class_error_rate = defaultdict(lambda: {'total': 0, 'errors': 0})\n",
        "\n",
        "    # Count total and error instances for each class\n",
        "    for true_label, pred_label in zip(y_true, y_pred):\n",
        "        true_class = cat_id_to_name[idx_to_cat_id[true_label]] if true_label in idx_to_cat_id else f\"Class {true_label}\"\n",
        "        class_error_rate[true_class]['total'] += 1\n",
        "        if true_label != pred_label:\n",
        "            class_error_rate[true_class]['errors'] += 1\n",
        "\n",
        "    # Calculate error rate for each class\n",
        "    error_rates = []\n",
        "    for class_name, counts in class_error_rate.items():\n",
        "        if counts['total'] > 0:\n",
        "            error_rate = counts['errors'] / counts['total']\n",
        "            error_rates.append((class_name, error_rate, counts['total'], counts['errors']))\n",
        "\n",
        "    # Sort by error rate in descending order\n",
        "    top_error_rates = sorted(error_rates, key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    # Visualize classes with highest error rates\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    classes = [err[0] for err in top_error_rates]\n",
        "    rates = [err[1] for err in top_error_rates]\n",
        "    totals = [err[2] for err in top_error_rates]\n",
        "\n",
        "    # Create x positions\n",
        "    x_pos = np.arange(len(top_error_rates))\n",
        "\n",
        "    # Create bar chart\n",
        "    bars = plt.barh(x_pos, rates, align='center', alpha=0.7)\n",
        "\n",
        "    # Add percentage and count labels\n",
        "    for i, bar in enumerate(bars):\n",
        "        plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "                f\"{rates[i]:.2f} ({top_error_rates[i][3]}/{totals[i]})\",\n",
        "                ha='left', va='center')\n",
        "\n",
        "    # Add labels\n",
        "    plt.yticks(x_pos, classes)\n",
        "    plt.xlabel('Error Rate')\n",
        "    plt.title('Classes with Highest Error Rates')\n",
        "    plt.xlim(0, max(rates) + 0.2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('highest_error_rates.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def calculate_map(y_true, y_pred, cat_id_to_name, idx_to_cat_id, outputs=None):\n",
        "    \"\"\"Calculate mean Average Precision (mAP)\"\"\"\n",
        "\n",
        "    # If we have raw outputs, use them for AP calculation\n",
        "    if outputs is not None:\n",
        "        # Convert outputs to numpy array if needed\n",
        "        if not isinstance(outputs, np.ndarray):\n",
        "            outputs = np.array(outputs)\n",
        "\n",
        "        # Number of classes\n",
        "        num_classes = outputs.shape[1]\n",
        "\n",
        "        # Convert labels to one-hot encoding\n",
        "        y_true_one_hot = np.zeros((len(y_true), num_classes))\n",
        "        for i, label in enumerate(y_true):\n",
        "            y_true_one_hot[i, label] = 1\n",
        "\n",
        "        # Calculate AP for each class\n",
        "        ap_per_class = {}\n",
        "        for cls_idx in range(num_classes):\n",
        "            if np.sum(y_true_one_hot[:, cls_idx]) > 0:  # Only calculate if the class appears in ground truth\n",
        "                class_ap = average_precision_score(y_true_one_hot[:, cls_idx], outputs[:, cls_idx])\n",
        "\n",
        "                # Get class name\n",
        "                if cls_idx in idx_to_cat_id:\n",
        "                    class_name = cat_id_to_name[idx_to_cat_id[cls_idx]]\n",
        "                else:\n",
        "                    class_name = f\"Class {cls_idx}\"\n",
        "\n",
        "                ap_per_class[class_name] = class_ap\n",
        "\n",
        "        # Calculate mAP\n",
        "        mAP = np.mean(list(ap_per_class.values()))\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\nðŸ“Š Mean Average Precision (mAP): {mAP:.4f}\")\n",
        "\n",
        "        # Print AP for each class\n",
        "        print(\"\\nðŸ“Š Average Precision per class:\")\n",
        "        for class_name, ap in sorted(ap_per_class.items(), key=lambda x: x[1], reverse=True):\n",
        "            print(f\"{class_name}: {ap:.4f}\")\n",
        "\n",
        "        # Visualize AP per class\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Sort classes by AP\n",
        "        sorted_ap = sorted(ap_per_class.items(), key=lambda x: x[1], reverse=True)\n",
        "        classes = [item[0] for item in sorted_ap]\n",
        "        aps = [item[1] for item in sorted_ap]\n",
        "\n",
        "        # Create bar chart\n",
        "        plt.bar(range(len(classes)), aps, align='center', alpha=0.7)\n",
        "\n",
        "        # Add AP value labels\n",
        "        for i, ap in enumerate(aps):\n",
        "            plt.text(i, ap + 0.02, f\"{ap:.3f}\", ha='center', va='bottom', rotation=0)\n",
        "\n",
        "        # Add labels\n",
        "        plt.xticks(range(len(classes)), classes, rotation=45, ha='right')\n",
        "        plt.ylabel('Average Precision')\n",
        "        plt.title('Average Precision per Class')\n",
        "        plt.ylim(0, 1.1)\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('average_precision_per_class.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        return mAP, ap_per_class\n",
        "    else:\n",
        "        # Without raw outputs, we can only approximate mAP using classification accuracy per class\n",
        "        print(\"\\nâš ï¸ Note: Raw model outputs not provided. Using class precision as approximation.\")\n",
        "\n",
        "        from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "        # Calculate precision, recall, and f1-score per class\n",
        "        precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "\n",
        "        # Get class names\n",
        "        class_names = []\n",
        "        unique_labels = sorted(set(y_true) | set(y_pred))\n",
        "        for label in unique_labels:\n",
        "            if label in idx_to_cat_id:\n",
        "                class_names.append(cat_id_to_name[idx_to_cat_id[label]])\n",
        "            else:\n",
        "                class_names.append(f\"Class {label}\")\n",
        "\n",
        "        # Calculate approximate mAP as average of precision scores\n",
        "        mAP = np.mean(precision)\n",
        "\n",
        "        # Create dictionary of class-wise precision\n",
        "        ap_per_class = {class_name: prec for class_name, prec in zip(class_names, precision)}\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\nðŸ“Š Approximate Mean Average Precision (mAP): {mAP:.4f}\")\n",
        "\n",
        "        # Print precision for each class\n",
        "        print(\"\\nðŸ“Š Precision per class:\")\n",
        "        for class_name, prec in sorted(ap_per_class.items(), key=lambda x: x[1], reverse=True):\n",
        "            print(f\"{class_name}: {prec:.4f}\")\n",
        "\n",
        "        # Visualize precision per class\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Sort classes by precision\n",
        "        sorted_prec = sorted(zip(class_names, precision), key=lambda x: x[1], reverse=True)\n",
        "        classes = [item[0] for item in sorted_prec]\n",
        "        precs = [item[1] for item in sorted_prec]\n",
        "\n",
        "        # Create bar chart\n",
        "        plt.bar(range(len(classes)), precs, align='center', alpha=0.7)\n",
        "\n",
        "        # Add precision value labels\n",
        "        for i, prec in enumerate(precs):\n",
        "            plt.text(i, prec + 0.02, f\"{prec:.3f}\", ha='center', va='bottom', rotation=0)\n",
        "\n",
        "        # Add labels\n",
        "        plt.xticks(range(len(classes)), classes, rotation=45, ha='right')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision per Class (mAP approximation)')\n",
        "        plt.ylim(0, 1.1)\n",
        "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('precision_per_class.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "        return mAP, ap_per_class\n",
        "\n",
        "def visualize_predictions(model, test_loader, cat_id_to_name, idx_to_cat_id, device, num_samples=5):\n",
        "    \"\"\"Visualize sample predictions with bounding boxes for ground truth and predictions\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Get random samples\n",
        "    sample_indices = random.sample(range(len(test_loader.dataset)), num_samples)\n",
        "\n",
        "    plt.figure(figsize=(15, 5*num_samples))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, sample_idx in enumerate(sample_indices):\n",
        "            image, label, img_path, bbox, original_image = test_loader.dataset[sample_idx]\n",
        "\n",
        "            # Skip if original image is None\n",
        "            if original_image is None:\n",
        "                continue\n",
        "\n",
        "            # Get prediction\n",
        "            input_tensor = image.unsqueeze(0).to(device)\n",
        "            outputs = model(input_tensor)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            pred_idx = pred.item()\n",
        "\n",
        "            # Get class names\n",
        "            true_class = cat_id_to_name[idx_to_cat_id[label]] if label in idx_to_cat_id else f\"Class {label}\"\n",
        "            pred_class = cat_id_to_name[idx_to_cat_id[pred_idx]] if pred_idx in idx_to_cat_id else f\"Class {pred_idx}\"\n",
        "\n",
        "            # Create visualization with ground truth\n",
        "            plt.subplot(num_samples, 2, idx*2 + 1)\n",
        "            img_with_gt = original_image.copy()\n",
        "            x, y, w, h = map(int, bbox)\n",
        "            cv2.rectangle(img_with_gt, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
        "            cv2.putText(img_with_gt, f\"GT: {true_class}\", (x, y-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "            plt.imshow(cv2.cvtColor(img_with_gt, cv2.COLOR_BGR2RGB))\n",
        "            plt.title('Ground Truth')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Create visualization with prediction\n",
        "            plt.subplot(num_samples, 2, idx*2 + 2)\n",
        "            img_with_pred = original_image.copy()\n",
        "            color = (0, 255, 0) if pred_idx == label else (0, 0, 255)\n",
        "            cv2.rectangle(img_with_pred, (x, y), (x+w, y+h), color, 3)\n",
        "            cv2.putText(img_with_pred, f\"Pred: {pred_class}\", (x, y-10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "            plt.imshow(cv2.cvtColor(img_with_pred, cv2.COLOR_BGR2RGB))\n",
        "            plt.title('Prediction')\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('prediction_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def test_model(dataset_path, model_path, mapping_path, batch_size=16):\n",
        "    \"\"\"Comprehensive test function with all requested features\"\"\"\n",
        "\n",
        "    print(\"ðŸ”„ Preparing test dataset...\")\n",
        "    test_loader, num_classes, cat_id_to_idx, cat_id_to_name = prepare_test_dataset(dataset_path, batch_size)\n",
        "    idx_to_cat_id = {v: k for k, v in cat_id_to_idx.items()}\n",
        "\n",
        "    # Load model\n",
        "    print(\"ðŸ”„ Loading model...\")\n",
        "    model = EfficientNetV2Model(num_classes).to(device)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    # Define criterion\n",
        "    criterion = FocalLoss(gamma=2.0)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"ðŸ”„ Evaluating on test set...\")\n",
        "    test_loss = 0.0\n",
        "    test_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_outputs = []  # Store raw model outputs for mAP calculation\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, *_ in tqdm(test_loader, desc=\"Testing\"):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            test_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_outputs.extend(outputs.cpu().numpy())  # Store raw outputs\n",
        "\n",
        "    test_loss = test_loss / total_samples\n",
        "    test_acc = test_corrects.double() / total_samples\n",
        "\n",
        "    print(f\"\\nðŸ“Š Test Results:\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Generate overall confusion matrix\n",
        "    print(\"\\nðŸ”„ Generating overall confusion matrix...\")\n",
        "    plot_confusion_matrix(all_labels, all_preds, cat_id_to_name, cat_id_to_idx, idx_to_cat_id, \"test\")\n",
        "\n",
        "    # Generate individual class confusion matrices\n",
        "    print(\"\\nðŸ”„ Generating individual class confusion matrices...\")\n",
        "    plot_per_class_confusion_matrix(all_labels, all_preds, cat_id_to_name, idx_to_cat_id)\n",
        "\n",
        "    # Analyze classification errors\n",
        "    print(\"\\nðŸ”„ Analyzing classification errors...\")\n",
        "    plot_error_analysis(all_labels, all_preds, cat_id_to_name, idx_to_cat_id)\n",
        "\n",
        "    # Calculate mean Average Precision (mAP)\n",
        "    print(\"\\nðŸ”„ Calculating mean Average Precision (mAP)...\")\n",
        "    mAP, ap_per_class = calculate_map(all_labels, all_preds, cat_id_to_name, idx_to_cat_id, all_outputs)\n",
        "\n",
        "    # Visualize sample predictions\n",
        "    print(\"\\nðŸ”„ Visualizing sample predictions...\")\n",
        "    visualize_predictions(model, test_loader, cat_id_to_name, idx_to_cat_id, device)\n",
        "\n",
        "    # Save test results\n",
        "    test_results = {\n",
        "        'test_loss': test_loss,\n",
        "        'test_accuracy': test_acc,\n",
        "        'predictions': all_preds,\n",
        "        'labels': all_labels,\n",
        "        'classification_report': classification_report(\n",
        "            all_labels, all_preds,\n",
        "            target_names=[cat_id_to_name[idx_to_cat_id[i]] if i in idx_to_cat_id else f\"Class {i}\"\n",
        "                         for i in sorted(set(all_labels) | set(all_preds))],\n",
        "            labels=sorted(set(all_labels) | set(all_preds)),\n",
        "            output_dict=True\n",
        "        ),\n",
        "        'mAP': mAP,\n",
        "        'ap_per_class': ap_per_class\n",
        "    }\n",
        "\n",
        "    with open('test_results.pkl', 'wb') as f:\n",
        "        pickle.dump(test_results, f)\n",
        "\n",
        "    print(\"\\nâœ… Testing completed successfully!\")\n",
        "    print(f\"Final test accuracy: {test_acc:.4f}\")\n",
        "    print(f\"Mean Average Precision (mAP): {mAP:.4f}\")\n",
        "\n",
        "# Run testing\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        test_model(\n",
        "            dataset_path='/content/vzrad2-4',\n",
        "            model_path='best_model.pth',\n",
        "            mapping_path='category_mapping.pkl',\n",
        "            batch_size=16\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Testing failed: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIadHVvy2CFQ"
      },
      "source": [
        "Ø§Ù„Ù„ÙŠ ÙÙˆÙ‚ Ù…Ù…ØªØ§Ø² Ø¨Ø³ ÙŠØ­ÙØ· Ù…Ø§ ÙŠØ·Ø¨Ø¹ ØŒ Ø§Ù„Ø­ÙŠÙ† Ø¨Ø·Ø¨Ø¹ :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CweGUdAj2IKc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
